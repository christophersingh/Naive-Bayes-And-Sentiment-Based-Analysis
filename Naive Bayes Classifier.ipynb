{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, string\n",
    "from nltk import FreqDist\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining all the function to read data, extract features and traing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the datasets\n",
    "path = 'C:\\\\tmp\\\\'\n",
    "filePrefix = 'training_'\n",
    "categories=['ARTS','SPORTS']\n",
    "minWordLength = 3\n",
    "maxWordLength = 20\n",
    "totArticles = 0\n",
    "\n",
    "dataset={}\n",
    "allFeatures=set()\n",
    "for category in categories:\n",
    "    fileName=path+filePrefix+category.lower()\n",
    "    f=open(fileName,'r')\n",
    "    dataset[category]=f.readlines()\n",
    "    f.close\n",
    "    totArticles+=len(dataset[category])\n",
    "\n",
    "# print dataset['ARTS']\n",
    "# print '==========================='\n",
    "# print dataset['SPORTS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the probabilities for each category (you can define any number of categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARTS - p(ARTS)=0.5\n",
      "SPORTS - p(SPORTS)=0.5\n"
     ]
    }
   ],
   "source": [
    "feature_count = {}\n",
    "category_count = {}\n",
    "probCat = {}\n",
    "\n",
    "# Calculate the probabilities for each category\n",
    "for category in categories:\n",
    "    probCat[category]=len(dataset[category])*1.0/totArticles\n",
    "    print (\"%s - p(%s)=%s\" % (category,category,probCat[category]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating term probabilities 𝑝(𝑡|C) and 𝑝(𝑡)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Frequencies for word 'team':\n",
      "F('team'|'ARTS')=1\n",
      "F('team'|'SPORTS')=19\n"
     ]
    }
   ],
   "source": [
    "freqWord = {}\n",
    "wordCounts = {}\n",
    "\n",
    "def buildFrequencies(dataset):\n",
    "    for category in categories:\n",
    "        freqWordCat = {}\n",
    "        count = 0\n",
    "        for article in dataset[category]:\n",
    "            #You can do a lot of optimization here\n",
    "            words = [w for w in word_tokenize(article)]\n",
    "            count+=len(words)\n",
    "            for word in words:\n",
    "                allFeatures.add(word)\n",
    "                if word in freqWordCat:\n",
    "                    freqWordCat[word] = freqWordCat[word]+1\n",
    "                else:\n",
    "                    freqWordCat[word] = 1\n",
    "        freqWord[category] = freqWordCat\n",
    "        wordCounts[category] = count\n",
    "\n",
    "\n",
    "#Generate frequencies\n",
    "buildFrequencies(dataset)\n",
    "\n",
    "print (\"Checking Frequencies for word 'team':\")\n",
    "print (\"F('team'|'ARTS')=%s\" % freqWord['ARTS']['team'])\n",
    "print (\"F('team'|'SPORTS')=%s\" % freqWord['SPORTS']['team'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From frequencies to probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability for word 'team' - p('team')=0.00320821302534\n",
      "probability for word 'team' in ARTS - p('team'|'ARTS')=0.000304043782305\n",
      "probability for word 'team' in SPORTS - p('team'|'SPORTS')=0.00645161290323\n"
     ]
    }
   ],
   "source": [
    "def getTermProbability(word):\n",
    "    count = 0\n",
    "    total = 0\n",
    "    for category in categories:\n",
    "        total += wordCounts[category]\n",
    "        if word in freqWord[category]:\n",
    "            count+=freqWord[category][word]\n",
    "    return count*1.0/total\n",
    "\n",
    "def getTermCondProbability(word,category):\n",
    "    count = 0\n",
    "    total = wordCounts[category]\n",
    "\n",
    "    if word in freqWord[category]:\n",
    "        count=freqWord[category][word]\n",
    "    else:\n",
    "        #Apply Laplace Smoothing\n",
    "        count=1.0/(len(freqWord[category])+len(allFeatures))\n",
    "    \n",
    "    return count*1.0/total\n",
    "    \n",
    "print (\"probability for word 'team' - p('team')=%s\" % getTermProbability('team'))\n",
    "print (\"probability for word 'team' in ARTS - p('team'|'ARTS')=%s\" % getTermCondProbability('team','ARTS'))\n",
    "print (\"probability for word 'team' in SPORTS - p('team'|'SPORTS')=%s\" % getTermCondProbability('team','SPORTS'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SPORTS'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def NaiveBayesClassifier(article):\n",
    "    words = [w for w in word_tokenize(article)]\n",
    "    results={}\n",
    "    for category in categories:\n",
    "        pCat = probCat[category]\n",
    "        pNumerator = 1.0\n",
    "        for word in words:\n",
    "            pN = getTermCondProbability(word,category)\n",
    "            pNumerator*= pN\n",
    "        pClassification = pNumerator*pCat\n",
    "        results[category] = pClassification\n",
    "    \n",
    "    pMax = 0.0\n",
    "    predictedClass = ''\n",
    "    for category in categories:\n",
    "        if results[category]>pMax:\n",
    "            pMax = results[category]\n",
    "            predictedClass = category\n",
    "\n",
    "    #print ('The article has been assigned to class \"%s\" with a probability of %s' % (predictedClass,pMax))\n",
    "    return predictedClass\n",
    "\n",
    "article = \"Without Any Title at Stake, Cavaliers Relive Rally Past Warriors\"\n",
    "NaiveBayesClassifier(article)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the Classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Prediction[SPORTS] Class[SPORTS]\n",
      "2. Prediction[ARTS] Class[SPORTS]\n",
      "3. Prediction[ARTS] Class[SPORTS]\n",
      "4. Prediction[SPORTS] Class[SPORTS]\n",
      "5. Prediction[ARTS] Class[SPORTS]\n",
      "6. Prediction[ARTS] Class[ARTS]\n",
      "7. Prediction[ARTS] Class[ARTS]\n",
      "8. Prediction[ARTS] Class[ARTS]\n",
      "9. Prediction[SPORTS] Class[ARTS]\n",
      "10. Prediction[SPORTS] Class[ARTS]\n",
      "\n",
      "The classifer was correct 5 out of 10 or 0.5\n",
      "precision=0.4\n",
      "recall=0.5\n",
      "F=0.444444444444\n"
     ]
    }
   ],
   "source": [
    "f=open('C:\\\\tmp\\\\testing.txt','r')\n",
    "lines=f.readlines()\n",
    "f.close\n",
    "\n",
    "correct = 0\n",
    "total = len(lines)\n",
    "index = 1\n",
    "\n",
    "TP=0.0\n",
    "TN=0.0\n",
    "FP=0.0\n",
    "FN=0.0\n",
    "\n",
    "F=0.0\n",
    "precision = 0.0\n",
    "recall = 0.0\n",
    "\n",
    "for line in lines:\n",
    "    elems = line.split('\\t')\n",
    "    article=elems[0]\n",
    "    category=elems[1][:-1]\n",
    "    predictedCategory = NaiveBayesClassifier(article)\n",
    "    \n",
    "    print '%s. Prediction[%s] Class[%s]' % (index,predictedCategory,category)\n",
    "    index+=1\n",
    "    \n",
    "    #Calculating quality measures\n",
    "    if (predictedCategory == category):\n",
    "        correct+=1\n",
    "        if (category == categories[1]):\n",
    "            TP+=1\n",
    "        else:\n",
    "            TN+=1\n",
    "    else:\n",
    "        if (predictedCategory == categories[1]):\n",
    "            FN+=1\n",
    "        else:\n",
    "            FP+=1\n",
    "\n",
    "precision = TP/(TP+FP)\n",
    "recall = TP/(TP+FN)\n",
    "F=2*(precision*recall)/(precision+recall)\n",
    "\n",
    "print ('\\nThe classifer was correct %s out of %s or %s' % (correct,total,correct*1.0/total))\n",
    "print 'precision=%s' % precision\n",
    "print 'recall=%s' % recall\n",
    "print 'F=%s' % F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
